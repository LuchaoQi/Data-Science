### Logistic regression

Loss function could be understood from MLE or gradient descent (Cross Entropy)

[Demystifying Cross-Entropy](https://medium.com/activating-robotic-minds/demystifying-cross-entropy-e80e3ad54a8)

[Understanding binary cross-entropy / log loss: a visual explanation](https://towardsdatascience.com/understanding-binary-cross-entropy-log-loss-a-visual-explanation-a3ac6025181a)

![image.png](https://i.loli.net/2020/01/07/S8cEajbtuhZ59KQ.png)

[Loss Function (Part II): Logistic Regression](https://towardsdatascience.com/optimization-loss-function-under-the-hood-part-ii-d20a239cde11)

[Notes from Coursera Deep Learning courses by Andrew Ng](https://www.slideshare.net/TessFerrandez/notes-from-coursera-deep-learning-courses-by-andrew-ng?from_action=save)

![](https://i.loli.net/2020/01/03/wkKFegULahqbJGM.png)