

Note: word vectors are sometimes called word embeddings or word representations. They are a distributed representation.



![image.png](https://i.loli.net/2020/02/14/Ne1aLZc63tC7YpR.png)





![image.png](https://i.loli.net/2020/02/14/MRIxiHSXezAZnhy.png)







### Resources



http://web.stanford.edu/class/cs224n/

http://web.stanford.edu/class/cs224n/slides/cs224n-2020-lecture01-wordvecs1.pdf

https://piazza.com/jhu/spring2020/cs482682/resources

[建模角度理解word embedding及tensorflow实现](https://www.jianshu.com/p/d44ce1e3ec2f)

https://nbviewer.jupyter.org/github/danielfrg/word2vec/blob/master/examples/word2vec.ipynb