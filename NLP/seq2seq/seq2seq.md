



[Attention学习_基础篇](https://mp.weixin.qq.com/s?__biz=MzU1Nzc1NjI0Nw==&mid=2247484964&idx=1&sn=e1e92a9673dcea13e0f6806c9e07c779&chksm=fc31bc1ccb46350a22b8cfaf7dc76bf811452fe6793ea99123de72219a2374a75fee580ea58a&mpshare=1&scene=1&srcid=0504qxlyZZxOfjAGIKWW3mnR&sharer_sharetime=1588543788810&sharer_shareid=54d7b6bf73b347d381a7bff3f78b99d1&key=d324c761f914ac8391efebde700bb39eddb1a66608cc3cb8977ea2f038ddaea02b42080e6a57bb2115377588dc32aed2720ae31080a8f1ca7c9185b72b5aee1dce8bc732308178e165933b8aa0e07b32&ascene=1&uin=NzA3NTE3MTMz&devicetype=Windows+10&version=62080085&lang=en&exportkey=A1jjUrMxA%2BY8%2FkqHxtCyOWE%3D&pass_ticket=PG5n9ZPUEJHhYjlHC8Uim96QI1xUIV34buzl9K5ZD7qhPMv7KmFwlkKHqFd5gmNN)                

[Attention — Seq2Seq Models](https://towardsdatascience.com/day-1-2-attention-seq2seq-models-65df3f49e263)

http://web.stanford.edu/class/cs20si/lectures/slides_13.pdf

[Intuitive Understanding of Seq2seq model & Attention Mechanism in Deep Learning](https://medium.com/analytics-vidhya/intuitive-understanding-of-seq2seq-model-attention-mechanism-in-deep-learning-1c1c24aace1e)

[Sequence-to-sequence Models](https://nlp.stanford.edu/~johnhew/public/14-seq2seq.pdf)







tf-seq2seq is a general-purpose encoder-decoder framework for Tensorflow that can be used for **Machine Translation, Text Summarization, Conversational Modeling, Image Captioning**, and more.

![](https://3.bp.blogspot.com/-3Pbj_dvt0Vo/V-qe-Nl6P5I/AAAAAAAABQc/z0_6WtVWtvARtMk0i9_AtLeyyGyV6AI4wCLcB/s1600/nmt-model-fast.gif)





![](https://miro.medium.com/max/5120/1*LYGO4IxqUYftFdAccg5fVQ.png)





### Code example

[Difference Between Return Sequences and Return States for LSTMs in Keras](https://machinelearningmastery.com/return-sequences-and-return-states-for-lstms-in-keras/)



[seq2seq (Sequence to Sequence) Model for Deep Learning with PyTorch](https://www.guru99.com/seq2seq-model.html)



[A ten-minute introduction to sequence-to-sequence learning in Keras](https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html)



[How to implement Seq2Seq LSTM Model in Keras #ShortcutNLP](https://towardsdatascience.com/how-to-implement-seq2seq-lstm-model-in-keras-shortcutnlp-6f355f3e5639)



