

CBOW

https://piazza.com/class_profile/get_resource/k5so7na4z3n3st/k6cr5719st54an



skip-gram

http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/

>The 300 features are learned by the neural network, and there's no obvious meaning that you can ascribe to them.
>The number 300 corresponds to the number of neurons in the hidden layer of the network. If you build your neural network with 100 neurons in the hidden layer, then your word vectors would have 100 features.







[Distributed Representations of Words and Phrases and their Compositionality](http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf)

http://cs224d.stanford.edu/lecture_notes/notes1.pdf

https://towardsdatascience.com/nlp-101-word2vec-skip-gram-and-cbow-93512ee24314

