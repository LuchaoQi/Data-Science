```{r message=F}
# library(checkpoint)
# checkpoint("2019-05-06", R.version = "3.5.3")

library(RCurl)
library(jsonlite)
library(caret)
library(e1071)
library(statmod)
library(MASS)
library(nnet)
library(neuralnet)
library(RSNNS)
library(deepnet)
library(darch)
library(h2o)


cl <- h2o.init(
 max_mem_size = "3G",
 nthreads = 2)

#local website 127.0.0.1:54321

h2oiris <- as.h2o(
 droplevels(iris[1:100, ]))


digits.train <- read.csv("train.csv")
digits.train$label <- factor(digits.train$label, levels = 0:9)
i <- 1:5000
digits.X <- digits.train[i, -1]
digits.y <- digits.train[i, 1]


# Finally, before we get started building our neural network, let's quickly check the
# distribution of the digits. This can be important as, for example, if one digit occurs very
# rarely, we may need to adjust our modeling approach to ensure that, even though it is
# rare, it is given enough weight in performance evaluation if we care about accurately
# predicting that digit as well. The following code snippet creates a bar plot showing the
# frequency of each digit label. They are fairly evenly distributed so there is
# no real need to increase the weight or importance given to any particular one:

barplot(table(digits.y))


digits.m1 <- caret::train(x = digits.X, y = digits.y,
 method = "nnet",
 tuneGrid = expand.grid(
 .size = c(5),
 .decay = 0.1),
 trControl = trainControl(method = "none"),
 MaxNWts = 10000,
 maxit = 100)


digits.yhat1 <- predict(digits.m1)
barplot(table(digits.yhat1))




```

